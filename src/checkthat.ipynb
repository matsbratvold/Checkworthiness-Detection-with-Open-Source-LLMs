{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of CheckThat 2021 Task 1a English dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Python modules and loading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from checkthat_utils import load_check_that_dataset, CheckThatLabel\n",
    "from plotting_utils import dataframe_to_text, show_word_cloud, show_bar_plot, show_histogram_plot, show_sub_plots_with_legends, show_sub_plots_pie_chart\n",
    "import os\n",
    "\n",
    "folder_path = os.path.join(\"../data\", \"CheckThat2021Task1a\")\n",
    "binary_verdicts = [CheckThatLabel.CHECK_WORTHY, CheckThatLabel.NON_CHECK_WORTHY]\n",
    "binary_data = load_check_that_dataset(folder_path)\n",
    "binary_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "categories = [\"All\", \"Check-worthy\", \"Non-check-worthy\"]\n",
    "titles = [f\"Word cloud for {category}\" for category in categories]\n",
    "base_dir = os.path.join(\"..\", \"figures\", \"checkthat\", \"wordclouds\")\n",
    "file_paths = [os.path.join(base_dir, f\"{category}.png\") for category in categories] \n",
    "verdicts = [None, CheckThatLabel.CHECK_WORTHY, CheckThatLabel.NON_CHECK_WORTHY]\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "for verdict, title, file_path in zip(verdicts, titles, file_paths):\n",
    "    if verdict is None:\n",
    "        text = dataframe_to_text(binary_data, labels=[\"tweet_text\"])\n",
    "    else:\n",
    "        filtered_data = binary_data[binary_data[\"check_worthiness\"] == verdict.value]\n",
    "        text = dataframe_to_text(filtered_data, labels=[\"tweet_text\"])\n",
    "    show_word_cloud(text, title, file_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
