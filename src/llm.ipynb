{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check-worthiness detection using Large Language Models\n",
    "\n",
    "First, the necessary python modules are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from claimbuster_utils import load_claimbuster_dataset\n",
    "from checkthat_utils import load_check_that_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from llm import load_huggingface_model, HuggingFaceModel, run_llm_cross_validation, ThresholdOptimizer\n",
    "import os\n",
    "from error_analysis import generate_error_analysis_report\n",
    "from dataset_utils import generate_cross_validation_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 720/720 [00:00<?, ?B/s] \n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m model_id \u001b[38;5;241m=\u001b[39m HuggingFaceModel\u001b[38;5;241m.\u001b[39mMIXTRAL_INSTRUCT\n\u001b[1;32m----> 3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mload_huggingface_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matsb\\source\\repos\\Fake-news-detection\\src\\llm.py:74\u001b[0m, in \u001b[0;36mload_huggingface_model\u001b[1;34m(model_id, bnb_config, max_new_tokens, return_full_text)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_huggingface_model\u001b[39m(\n\u001b[0;32m     67\u001b[0m     model_id: HuggingFaceModel, \n\u001b[0;32m     68\u001b[0m     bnb_config\u001b[38;5;241m=\u001b[39mBNB_CONFIG,\n\u001b[0;32m     69\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m     70\u001b[0m     return_full_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Pipeline: \n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a Huggingface LLM model as a pipeline. Note that this has only been tested\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    with models from Mistral, so it might not work with other models.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    567\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\transformers\\modeling_utils.py:2945\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2943\u001b[0m         )\n\u001b[0;32m   2944\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 2945\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2946\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2947\u001b[0m         )\n\u001b[0;32m   2949\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[0;32m   2950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[1;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "model_id = HuggingFaceModel.MIXTRAL_INSTRUCT\n",
    "pipe = load_huggingface_model(model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClaimBuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m     36\u001b[0m prompts_data \u001b[38;5;241m=\u001b[39m ProgressDataset(prompts)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpipe\u001b[49m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(prompts_data))\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# dataset_with_scores = data.copy()\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# display(data.head())\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# dataset_with_scores = dataset_with_scores[columns]\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# dataset_with_scores.to_csv(zeroshot_output, index=True)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"../prompts/ClaimBuster/standard/zero-shot.txt\", \"r\") as f:\n",
    "    instruction = f.read().replace(\"\\n\", \"\")\n",
    "use_contextual = False\n",
    "data = load_claimbuster_dataset(\n",
    "    \"../data/ClaimBuster_Datasets/datasets\",\n",
    "    use_contextual_features=use_contextual,\n",
    "    debate_transcripts_folder=\"../data/ClaimBuster_Datasets/debate_transcripts\",\n",
    ")[:10]\n",
    "\n",
    "\n",
    "texts = data[\"Text\"]\n",
    "if use_contextual is False:\n",
    "    prompts = [f\"{instruction} '''{text}'''\" for text in texts]\n",
    "    zeroshot_output = f\"../results/ClaimBuster/{model_id.name}/zeroshot/zeroshot1.csv\"\n",
    "    os.makedirs(os.path.dirname(zeroshot_output), exist_ok=True)\n",
    "else:\n",
    "    contexts = data[\"previous_sentences\"].tolist()\n",
    "    prompts = [\n",
    "        f\"{instruction} For context, the following senteces were said prior to the one in question: {context} Only evaluate the check-worthiness of the following sentence: '''{text}'''\"\n",
    "        for text, context in zip(texts, contexts)\n",
    "    ]\n",
    "    zeroshot_output = \"../results/ClaimBuster/zeroshot_contextual.csv\"\n",
    "\n",
    "\n",
    "class ProgressDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "prompts_data = ProgressDataset(prompts)\n",
    "print(pipe.tokenizer.encode(prompts_data))\n",
    "\n",
    "dataset_with_scores = data.copy()\n",
    "\n",
    "display(data.head())\n",
    "dict_matcher = re.compile(r\"{.*}\")\n",
    "score_matcher = re.compile(r\"([Ss]core[^\\d]*)(\\d+)\")\n",
    "non_check_worthy_matcher = re.compile(\n",
    "    r\"(non-checkworthy)|(not check-worthy)|(non check-worthy)\"\n",
    ")\n",
    "\n",
    "responses = pipe(prompts_data, batch_size=128)\n",
    "for index, result in enumerate(tqdm(responses, total=len(prompts))):\n",
    "    response = result[0][\"generated_text\"].replace(\"\\n\", \"\")\n",
    "    dataset_index = data.index[index]\n",
    "    try:\n",
    "        parsed_json = json.loads(dict_matcher.search(response).group(0))\n",
    "        dataset_with_scores.loc[dataset_index, \"score\"] = parsed_json[\"score\"]\n",
    "        dataset_with_scores.loc[dataset_index, \"reasoning\"] = parsed_json[\"reasoning\"]\n",
    "    except (json.decoder.JSONDecodeError, AttributeError, KeyError) as e:\n",
    "        # Try to find score\n",
    "        score = score_matcher.search(response)\n",
    "        if score is not None:\n",
    "            score = score[2]\n",
    "        else:\n",
    "            score = 0.0 if non_check_worthy_matcher.search(response) else np.nan\n",
    "        dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
    "        dataset_with_scores.loc[dataset_index, \"reasoning\"] = response\n",
    "        continue\n",
    "# Set the following column order: Verdict, score, Text, reasoning, previous_sentences\n",
    "columns =  [\"Verdict\", \"score\", \"Text\", \"reasoning\"]\n",
    "if use_contextual:\n",
    "    columns.append(\"previous_sentences\")\n",
    "dataset_with_scores = dataset_with_scores[columns]\n",
    "dataset_with_scores.to_csv(zeroshot_output, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 fold cross validation for model MISTRAL_7B_INSTRUCT\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/ClaimBuster/MISTRAL_7B_INSTRUCT/zeroshot/zeroshot1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning 4 fold cross validation for model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../results/ClaimBuster/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/zeroshot/zeroshot1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m dataset_with_scores \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m save_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../results/ClaimBuster/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/zeroshot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m result \u001b[38;5;241m=\u001b[39m run_llm_cross_validation(\n\u001b[0;32m     10\u001b[0m     data\u001b[38;5;241m=\u001b[39mdataset_with_scores, crossval_folder\u001b[38;5;241m=\u001b[39mcrossval_folder, save_folder\u001b[38;5;241m=\u001b[39msave_folder\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/ClaimBuster/MISTRAL_7B_INSTRUCT/zeroshot/zeroshot1.csv'"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "crossval_folder = \"../data/ClaimBuster_Datasets/crossval\"\n",
    "for model_id in HuggingFaceModel:\n",
    "    print(f\"Running 4 fold cross validation for model {model_id.name}\")\n",
    "    dataset_path = f\"../results/ClaimBuster/{model_id.name}/zeroshot/zeroshot1.csv\"\n",
    "    dataset_with_scores = pd.read_csv(dataset_path, index_col=0)\n",
    "    save_folder = f\"../results/ClaimBuster/{model_id.name}/zeroshot\"\n",
    "    result = run_llm_cross_validation(\n",
    "        data=dataset_with_scores, crossval_folder=crossval_folder, save_folder=save_folder\n",
    "    )\n",
    "    \n",
    "    display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#              MISTRAL_7B_INSTRUCT               #\n",
      "#              False positives: 413              #\n",
      "#              False negatives: 624              #\n",
      "#              Empty predictions: 0              #\n",
      "#             Wrong output format: 0             #\n",
      "##################################################\n",
      "#                MIXTRAL_INSTRUCT                #\n",
      "#             False positives: 1193              #\n",
      "#              False negatives: 388              #\n",
      "#              Empty predictions: 8              #\n",
      "#            Wrong output format: 259            #\n",
      "##################################################\n",
      "#                     Total                      #\n",
      "#             False positives: 1324              #\n",
      "#              False negatives: 757              #\n",
      "#        Overlapping false positives: 282        #\n",
      "#        Overlapping false negatives: 255        #\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "mistral_results = pd.read_csv(f\"../results/ClaimBuster/{HuggingFaceModel.MISTRAL_7B_INSTRUCT.name}/zeroshot1.csv\", index_col=0)\n",
    "mixtral_results = pd.read_csv(f\"../results/ClaimBuster/{HuggingFaceModel.MIXTRAL_INSTRUCT.name}/zeroshot1.csv\", index_col=0)\n",
    "results = [mistral_results, mixtral_results]\n",
    "models = [HuggingFaceModel.MISTRAL_7B_INSTRUCT, HuggingFaceModel.MIXTRAL_INSTRUCT]\n",
    "generate_error_analysis_report(\n",
    "    results=results,\n",
    "    models=models,\n",
    "    folder_path=f\"../results/ClaimBuster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CheckThat 2021 Task 1a Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  25981 MiB |  25981 MiB | 114559 MiB |  88578 MiB |\n",
      "|       from large pool |  25899 MiB |  25899 MiB | 114475 MiB |  88576 MiB |\n",
      "|       from small pool |     81 MiB |     81 MiB |     83 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  25981 MiB |  25981 MiB | 114559 MiB |  88578 MiB |\n",
      "|       from large pool |  25899 MiB |  25899 MiB | 114475 MiB |  88576 MiB |\n",
      "|       from small pool |     81 MiB |     81 MiB |     83 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  25925 MiB |  25925 MiB | 114503 MiB |  88578 MiB |\n",
      "|       from large pool |  25844 MiB |  25844 MiB | 114420 MiB |  88576 MiB |\n",
      "|       from small pool |     81 MiB |     81 MiB |     83 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  26318 MiB |  26318 MiB |  29934 MiB |   3616 MiB |\n",
      "|       from large pool |  26236 MiB |  26236 MiB |  29852 MiB |   3616 MiB |\n",
      "|       from small pool |     82 MiB |     82 MiB |     82 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 345048 KiB | 353240 KiB |   7465 MiB |   7128 MiB |\n",
      "|       from large pool | 344576 KiB | 352768 KiB |   7415 MiB |   7079 MiB |\n",
      "|       from small pool |    472 KiB |   2090 KiB |     50 MiB |     49 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    2947    |    2947    |    3875    |     928    |\n",
      "|       from large pool |    1730    |    1730    |    2626    |     896    |\n",
      "|       from small pool |    1217    |    1217    |    1249    |      32    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    2947    |    2947    |    3875    |     928    |\n",
      "|       from large pool |    1730    |    1730    |    2626    |     896    |\n",
      "|       from small pool |    1217    |    1217    |    1249    |      32    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     969    |     969    |    1002    |      33    |\n",
      "|       from large pool |     928    |     928    |     961    |      33    |\n",
      "|       from small pool |      41    |      41    |      41    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     123    |     123    |     336    |     213    |\n",
      "|       from large pool |     121    |     121    |     275    |     154    |\n",
      "|       from small pool |       2    |       5    |      61    |      59    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>claim</th>\n",
       "      <th>check_worthiness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234964653014384644</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/EricTrump/status/123496465...</td>\n",
       "      <td>Since this will never get reported by the medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234869939720216578</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/RealJamesWoods/status/1234...</td>\n",
       "      <td>Thanks, #MichaelBloomberg. Here’s a handy litt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234873136304267267</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/hayxsmith/status/123487313...</td>\n",
       "      <td>Folks, when you say \"The corona virus isn't a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235071285027147776</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/ipspankajnain/status/12350...</td>\n",
       "      <td>Just 1 case of Corona Virus in India and  peop...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234911110861594624</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/PressSec/status/1234911110...</td>\n",
       "      <td>President  @realDonaldTrump  made a commitment...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     topic_id  \\\n",
       "tweet_id                        \n",
       "1234964653014384644  covid-19   \n",
       "1234869939720216578  covid-19   \n",
       "1234873136304267267  covid-19   \n",
       "1235071285027147776  covid-19   \n",
       "1234911110861594624  covid-19   \n",
       "\n",
       "                                                             tweet_url  \\\n",
       "tweet_id                                                                 \n",
       "1234964653014384644  https://twitter.com/EricTrump/status/123496465...   \n",
       "1234869939720216578  https://twitter.com/RealJamesWoods/status/1234...   \n",
       "1234873136304267267  https://twitter.com/hayxsmith/status/123487313...   \n",
       "1235071285027147776  https://twitter.com/ipspankajnain/status/12350...   \n",
       "1234911110861594624  https://twitter.com/PressSec/status/1234911110...   \n",
       "\n",
       "                                                            tweet_text  claim  \\\n",
       "tweet_id                                                                        \n",
       "1234964653014384644  Since this will never get reported by the medi...      1   \n",
       "1234869939720216578  Thanks, #MichaelBloomberg. Here’s a handy litt...      0   \n",
       "1234873136304267267  Folks, when you say \"The corona virus isn't a ...      0   \n",
       "1235071285027147776  Just 1 case of Corona Virus in India and  peop...      1   \n",
       "1234911110861594624  President  @realDonaldTrump  made a commitment...      1   \n",
       "\n",
       "                     check_worthiness  \n",
       "tweet_id                               \n",
       "1234964653014384644                 1  \n",
       "1234869939720216578                 0  \n",
       "1234873136304267267                 0  \n",
       "1235071285027147776                 0  \n",
       "1234911110861594624                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1172 [02:12<42:59:55, 132.19s/it]/tmp/ipykernel_1771071/3923584380.py:52: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
      "100%|██████████| 1172/1172 [22:23<00:00,  1.15s/it] \n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "print(torch.cuda.memory_summary())\n",
    "with open(\"../prompts/CheckThat/standard/zero-shot.txt\", \"r\") as f:\n",
    "    instruction = f.read().replace(\"\\n\", \"\")\n",
    "data = load_check_that_dataset(\n",
    "    \"../data/CheckThat2021Task1a\",\n",
    ")\n",
    "\n",
    "texts = data[\"tweet_text\"]\n",
    "prompts = [f\"{instruction} '''{text}'''\" for text in texts]\n",
    "zeroshot_output = f\"../results/CheckThat/{model_id.name}/zeroshot1.csv\"\n",
    "os.makedirs(os.path.dirname(zeroshot_output), exist_ok=True)\n",
    "\n",
    "class ProgressDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "prompts_data = ProgressDataset(prompts)\n",
    "\n",
    "dataset_with_scores = data.copy()\n",
    "\n",
    "display(data.head())\n",
    "dict_matcher = re.compile(r\"{.*}\")\n",
    "score_matcher = re.compile(r\"([Ss]core[^\\d]*)(\\d+)\")\n",
    "non_check_worthy_matcher = re.compile(\n",
    "    r\"(non-checkworthy)|(not check-worthy)|(non check-worthy)\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    responses = pipe(prompts_data, batch_size=128)\n",
    "    for index, result in enumerate(tqdm(responses, total=len(prompts))):\n",
    "        response = result[0][\"generated_text\"].replace(\"\\n\", \"\")\n",
    "        dataset_index = data.index[index]\n",
    "        try:\n",
    "            parsed_json = json.loads(dict_matcher.search(response).group(0))\n",
    "            dataset_with_scores.loc[dataset_index, \"score\"] = parsed_json[\"score\"]\n",
    "            dataset_with_scores.loc[dataset_index, \"reasoning\"] = parsed_json[\"reasoning\"]\n",
    "        except (json.decoder.JSONDecodeError, AttributeError, KeyError) as e:\n",
    "            # Try to find score\n",
    "            score = score_matcher.search(response)\n",
    "            if score is not None:\n",
    "                score = score[2]\n",
    "            else:\n",
    "                score = 0.0 if non_check_worthy_matcher.search(response) else np.nan\n",
    "            dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
    "            dataset_with_scores.loc[dataset_index, \"reasoning\"] = response\n",
    "            continue\n",
    "columns =  [\"check_worthiness\", \"score\", \"tweet_text\", \"reasoning\"]\n",
    "dataset_with_scores = dataset_with_scores[columns]\n",
    "dataset_with_scores.to_csv(zeroshot_output, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 fold cross validation for model MISTRAL_7B_INSTRUCT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>0_precision</th>\n",
       "      <th>0_recall</th>\n",
       "      <th>0_f1-score</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.645051</td>\n",
       "      <td>0.828402</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.395161</td>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.485149</td>\n",
       "      <td>0.611782</td>\n",
       "      <td>0.639684</td>\n",
       "      <td>0.607158</td>\n",
       "      <td>0.713069</td>\n",
       "      <td>0.645051</td>\n",
       "      <td>0.664206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607509</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.672365</td>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.626910</td>\n",
       "      <td>0.662759</td>\n",
       "      <td>0.591501</td>\n",
       "      <td>0.744166</td>\n",
       "      <td>0.607509</td>\n",
       "      <td>0.629863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.672355</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.418803</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.505155</td>\n",
       "      <td>0.629856</td>\n",
       "      <td>0.660774</td>\n",
       "      <td>0.630128</td>\n",
       "      <td>0.729980</td>\n",
       "      <td>0.672355</td>\n",
       "      <td>0.689416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.657407</td>\n",
       "      <td>0.735751</td>\n",
       "      <td>0.398374</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.616834</td>\n",
       "      <td>0.646886</td>\n",
       "      <td>0.612876</td>\n",
       "      <td>0.720472</td>\n",
       "      <td>0.651877</td>\n",
       "      <td>0.671168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.644198</td>\n",
       "      <td>0.844670</td>\n",
       "      <td>0.635013</td>\n",
       "      <td>0.723096</td>\n",
       "      <td>0.398021</td>\n",
       "      <td>0.670038</td>\n",
       "      <td>0.497735</td>\n",
       "      <td>0.621346</td>\n",
       "      <td>0.652526</td>\n",
       "      <td>0.610416</td>\n",
       "      <td>0.726922</td>\n",
       "      <td>0.644198</td>\n",
       "      <td>0.663663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  0_precision  0_recall  0_f1-score  1_precision  1_recall  \\\n",
       "0        0.645051     0.828402  0.651163    0.729167     0.395161  0.628205   \n",
       "1        0.607509     0.874074  0.546296    0.672365     0.379747  0.779221   \n",
       "2        0.672355     0.840909  0.685185    0.755102     0.418803  0.636364   \n",
       "3        0.651877     0.835294  0.657407    0.735751     0.398374  0.636364   \n",
       "Average  0.644198     0.844670  0.635013    0.723096     0.398021  0.670038   \n",
       "\n",
       "         1_f1-score  macro avg_precision  macro avg_recall  \\\n",
       "0          0.485149             0.611782          0.639684   \n",
       "1          0.510638             0.626910          0.662759   \n",
       "2          0.505155             0.629856          0.660774   \n",
       "3          0.490000             0.616834          0.646886   \n",
       "Average    0.497735             0.621346          0.652526   \n",
       "\n",
       "         macro avg_f1-score  weighted avg_precision  weighted avg_recall  \\\n",
       "0                  0.607158                0.713069             0.645051   \n",
       "1                  0.591501                0.744166             0.607509   \n",
       "2                  0.630128                0.729980             0.672355   \n",
       "3                  0.612876                0.720472             0.651877   \n",
       "Average            0.610416                0.726922             0.644198   \n",
       "\n",
       "         weighted avg_f1-score  \n",
       "0                     0.664206  \n",
       "1                     0.629863  \n",
       "2                     0.689416  \n",
       "3                     0.671168  \n",
       "Average               0.663663  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 fold cross validation for model MIXTRAL_INSTRUCT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>0_precision</th>\n",
       "      <th>0_recall</th>\n",
       "      <th>0_f1-score</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>macro avg_precision</th>\n",
       "      <th>macro avg_recall</th>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.809302</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.652201</td>\n",
       "      <td>0.654651</td>\n",
       "      <td>0.653377</td>\n",
       "      <td>0.729211</td>\n",
       "      <td>0.726962</td>\n",
       "      <td>0.728053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.778157</td>\n",
       "      <td>0.864734</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.846336</td>\n",
       "      <td>0.569767</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.601227</td>\n",
       "      <td>0.717251</td>\n",
       "      <td>0.732534</td>\n",
       "      <td>0.723781</td>\n",
       "      <td>0.787217</td>\n",
       "      <td>0.778157</td>\n",
       "      <td>0.781921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.847291</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.821002</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.550898</td>\n",
       "      <td>0.679201</td>\n",
       "      <td>0.696849</td>\n",
       "      <td>0.685950</td>\n",
       "      <td>0.758943</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.750019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.754266</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.686489</td>\n",
       "      <td>0.695437</td>\n",
       "      <td>0.690493</td>\n",
       "      <td>0.760670</td>\n",
       "      <td>0.754266</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.750853</td>\n",
       "      <td>0.842946</td>\n",
       "      <td>0.813437</td>\n",
       "      <td>0.827852</td>\n",
       "      <td>0.524625</td>\n",
       "      <td>0.576299</td>\n",
       "      <td>0.548949</td>\n",
       "      <td>0.683785</td>\n",
       "      <td>0.694868</td>\n",
       "      <td>0.688401</td>\n",
       "      <td>0.759010</td>\n",
       "      <td>0.750853</td>\n",
       "      <td>0.754284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  0_precision  0_recall  0_f1-score  1_precision  1_recall  \\\n",
       "0        0.726962     0.816901  0.809302    0.813084     0.487500  0.500000   \n",
       "1        0.778157     0.864734  0.828704    0.846336     0.569767  0.636364   \n",
       "2        0.744027     0.847291  0.796296    0.821002     0.511111  0.597403   \n",
       "3        0.754266     0.842857  0.819444    0.830986     0.530120  0.571429   \n",
       "Average  0.750853     0.842946  0.813437    0.827852     0.524625  0.576299   \n",
       "\n",
       "         1_f1-score  macro avg_precision  macro avg_recall  \\\n",
       "0          0.493671             0.652201          0.654651   \n",
       "1          0.601227             0.717251          0.732534   \n",
       "2          0.550898             0.679201          0.696849   \n",
       "3          0.550000             0.686489          0.695437   \n",
       "Average    0.548949             0.683785          0.694868   \n",
       "\n",
       "         macro avg_f1-score  weighted avg_precision  weighted avg_recall  \\\n",
       "0                  0.653377                0.729211             0.726962   \n",
       "1                  0.723781                0.787217             0.778157   \n",
       "2                  0.685950                0.758943             0.744027   \n",
       "3                  0.690493                0.760670             0.754266   \n",
       "Average            0.688401                0.759010             0.750853   \n",
       "\n",
       "         weighted avg_f1-score  \n",
       "0                     0.728053  \n",
       "1                     0.781921  \n",
       "2                     0.750019  \n",
       "3                     0.757143  \n",
       "Average               0.754284  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload\n",
    "crossval_folder = \"../data/CheckThat2021Task1a/crossval\"\n",
    "for model_id in HuggingFaceModel:\n",
    "    print(f\"Running 4 fold cross validation for model {model_id.name}\")\n",
    "    dataset_path = f\"../results/CheckThat/{model_id.name}/zeroshot/zeroshot1.csv\"\n",
    "    dataset_with_scores = pd.read_csv(dataset_path, index_col=0)\n",
    "    save_folder = f\"../results/CheckThat/{model_id.name}/zeroshot\"\n",
    "    result = run_llm_cross_validation(\n",
    "        data=dataset_with_scores,\n",
    "        label_column=\"check_worthiness\",\n",
    "        crossval_folder=crossval_folder,\n",
    "        save_folder=save_folder,\n",
    "    )\n",
    "    display(result)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#              MISTRAL_7B_INSTRUCT               #\n",
      "#              False positives: 376              #\n",
      "#              False negatives: 36               #\n",
      "#              Empty predictions: 1              #\n",
      "#             Wrong output format: 0             #\n",
      "##################################################\n",
      "#                MIXTRAL_INSTRUCT                #\n",
      "#              False positives: 484              #\n",
      "#              False negatives: 20               #\n",
      "#              Empty predictions: 3              #\n",
      "#            Wrong output format: 25             #\n",
      "##################################################\n",
      "#                     Total                      #\n",
      "#              False positives: 568              #\n",
      "#              False negatives: 51               #\n",
      "#        Overlapping false positives: 292        #\n",
      "#         Overlapping false negatives: 5         #\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "folder_path = f\"../results/CheckThat\"\n",
    "mistral_results = pd.read_csv(f\"{folder_path}/{HuggingFaceModel.MISTRAL_7B_INSTRUCT.name}/zeroshot1.csv\", index_col=0)\n",
    "mixtral_results = pd.read_csv(f\"{folder_path}/{HuggingFaceModel.MIXTRAL_INSTRUCT.name}/zeroshot1.csv\", index_col=0)\n",
    "results = [mistral_results, mixtral_results]\n",
    "models = [HuggingFaceModel.MISTRAL_7B_INSTRUCT, HuggingFaceModel.MIXTRAL_INSTRUCT]\n",
    "generate_error_analysis_report(\n",
    "    results=results,\n",
    "    models=models,\n",
    "    folder_path=folder_path,\n",
    "    label_column_name=\"check_worthiness\",\n",
    "    text_column_name=\"tweet_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LORA finetuning\n",
    "\n",
    "Using LORA to fine-tune the Mistral 7B Instruct model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claimbuster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate cross validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "claimbuster = load_claimbuster_dataset(\"../data/ClaimBuster_Datasets/datasets\")\n",
    "datasets = generate_cross_validation_datasets(claimbuster, folder_path=\"../data/ClaimBuster_Datasets/crossval\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkthat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate cross validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkthat = load_check_that_dataset(\"../data/CheckThat2021Task1a\")\n",
    "datasets = generate_cross_validation_datasets(\n",
    "    checkthat, \n",
    "    label_column=\"check_worthiness\",\n",
    "    folder_path=\"../data/CheckThat2021Task1a/crossval\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
