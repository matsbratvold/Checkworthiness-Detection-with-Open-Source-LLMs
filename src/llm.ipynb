{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check-worthiness detection using Large Language Models\n",
    "\n",
    "First, the necessary python modules are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/matssbra/.conda/envs/fakeNews/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-04 16:36:47.926216: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 16:36:47.966004: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 16:36:47.966034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 16:36:47.967281: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 16:36:47.975181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 16:36:49.023075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from claimbuster_utils import load_claimbuster_dataset\n",
    "from checkthat_utils import load_check_that_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from llm import load_huggingface_model, HuggingFaceModel\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 19/19 [01:54<00:00,  6.03s/it]\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "model_id = HuggingFaceModel.MIXTRAL_INSTRUCT\n",
    "pipe = load_huggingface_model(model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClaimBuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27247</th>\n",
       "      <td>1</td>\n",
       "      <td>We're 9 million jobs short of that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10766</th>\n",
       "      <td>1</td>\n",
       "      <td>You know, last year up to this time, we've los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>1</td>\n",
       "      <td>And in November of 1975 I was the first presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19700</th>\n",
       "      <td>1</td>\n",
       "      <td>And what we've done during the Bush administra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>1</td>\n",
       "      <td>Do you know we don't have a single program spo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Verdict                                               Text\n",
       "sentence_id                                                            \n",
       "27247              1                We're 9 million jobs short of that.\n",
       "10766              1  You know, last year up to this time, we've los...\n",
       "3327               1  And in November of 1975 I was the first presid...\n",
       "19700              1  And what we've done during the Bush administra...\n",
       "12600              1  Do you know we don't have a single program spo..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 298/9674 [01:42<39:52,  3.92it/s]  /tmp/ipykernel_4125055/2661599538.py:60: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
      "100%|██████████| 9674/9674 [31:28<00:00,  5.12it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"../prompts/ClaimBuster/standard/zero-shot.txt\", \"r\") as f:\n",
    "    instruction = f.read().replace(\"\\n\", \"\")\n",
    "use_contextual = False\n",
    "data = load_claimbuster_dataset(\n",
    "    \"../data/ClaimBuster_Datasets/datasets\",\n",
    "    use_contextual_features=use_contextual,\n",
    "    debate_transcripts_folder=\"../data/ClaimBuster_Datasets/debate_transcripts\",\n",
    ")\n",
    "\n",
    "texts = data[\"Text\"]\n",
    "if use_contextual is False:\n",
    "    prompts = [f\"{instruction} '''{text}'''\" for text in texts]\n",
    "    zeroshot_output = f\"../results/ClaimBuster/{model_id.name}/zeroshot1.csv\"\n",
    "else:\n",
    "    contexts = data[\"previous_sentences\"].tolist()\n",
    "    prompts = [\n",
    "        f\"{instruction} For context, the following senteces were said prior to the one in question: {context} Only evaluate the check-worthiness of the following sentence: '''{text}'''\"\n",
    "        for text, context in zip(texts, contexts)\n",
    "    ]\n",
    "    zeroshot_output = \"../results/ClaimBuster/zeroshot_contextual.csv\"\n",
    "\n",
    "\n",
    "class ProgressDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "prompts_data = ProgressDataset(prompts)\n",
    "\n",
    "dataset_with_scores = data.copy()\n",
    "\n",
    "display(data.head())\n",
    "dict_matcher = re.compile(r\"{.*}\")\n",
    "score_matcher = re.compile(r\"([Ss]core[^\\d]*)(\\d+)\")\n",
    "non_check_worthy_matcher = re.compile(\n",
    "    r\"(non-checkworthy)|(not check-worthy)|(non check-worthy)\"\n",
    ")\n",
    "\n",
    "responses = pipe(prompts_data, batch_size=128)\n",
    "for index, result in enumerate(tqdm(responses, total=len(prompts))):\n",
    "    response = result[0][\"generated_text\"].replace(\"\\n\", \"\")\n",
    "    dataset_index = data.index[index]\n",
    "    try:\n",
    "        parsed_json = json.loads(dict_matcher.search(response).group(0))\n",
    "        dataset_with_scores.loc[dataset_index, \"score\"] = parsed_json[\"score\"]\n",
    "        dataset_with_scores.loc[dataset_index, \"reasoning\"] = parsed_json[\"reasoning\"]\n",
    "    except (json.decoder.JSONDecodeError, AttributeError) as e:\n",
    "        # Try to find score\n",
    "        score = score_matcher.search(response)\n",
    "        if score is not None:\n",
    "            score = score[2]\n",
    "        else:\n",
    "            score = 0.0 if non_check_worthy_matcher.search(response) else np.nan\n",
    "        dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
    "        dataset_with_scores.loc[dataset_index, \"reasoning\"] = response\n",
    "        continue\n",
    "# Set the following column order: Verdict, score, Text, reasoning, previous_sentences\n",
    "columns =  [\"Verdict\", \"score\", \"Text\", \"reasoning\"]\n",
    "if use_contextual:\n",
    "    columns.append(\"previous_sentences\")\n",
    "dataset_with_scores = dataset_with_scores[columns]\n",
    "dataset_with_scores.to_csv(zeroshot_output, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([1.28376102, 1.50472569, 1.22792745, 1.2808435 ]), 'score_time': array([0.00417757, 0.0038116 , 0.00471807, 0.00366807]), 'test_f1_macro': array([0.64137709, 0.63468915, 0.62384077, 0.62942657]), 'test_accuracy': array([0.68168665, 0.68582059, 0.66956162, 0.67162945])}\n"
     ]
    }
   ],
   "source": [
    "# Print the number of empty scores\n",
    "dataset_path = \"../results/ClaimBuster/zeroshot_contextual.csv\"\n",
    "dataset_with_scores = pd.read_csv(dataset_path, index_col=0)\n",
    "class ThresholdOptimizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.threshold = None\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, y: pd.Series):\n",
    "        \n",
    "        y_gold = x[\"Verdict\"].values\n",
    "\n",
    "        reports = []\n",
    "        for threshold in range(1, 100):\n",
    "            y_pred = x[\"score\"].map(lambda x: 1 if x >= threshold else 0).values\n",
    "            report = classification_report(y_gold, y_pred, output_dict=True)\n",
    "            report[\"threshold\"] = threshold\n",
    "            reports.append(report)\n",
    "        self.threshold = max(reports, key=lambda report: report[\"macro avg\"][\"f1-score\"])[\"threshold\"]\n",
    "    \n",
    "    def predict(self, x: pd.DataFrame):\n",
    "        predictions = x[\"score\"].map(lambda x: 1 if x >= self.threshold else 0)\n",
    "        return predictions\n",
    "\n",
    "# Do a four fold cross validation where the threshold is optimized\n",
    "print(cross_validate(\n",
    "    ThresholdOptimizer(),\n",
    "    X=dataset_with_scores,\n",
    "    y=dataset_with_scores[\"Verdict\"],\n",
    "    cv=StratifiedKFold(n_splits=4),\n",
    "    scoring=[\"f1_macro\", \"accuracy\"],\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CheckThat 2021 Task 1a Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  25981 MiB |  25981 MiB | 114559 MiB |  88578 MiB |\n",
      "|       from large pool |  25899 MiB |  25899 MiB | 114475 MiB |  88576 MiB |\n",
      "|       from small pool |     81 MiB |     81 MiB |     83 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  25981 MiB |  25981 MiB | 114559 MiB |  88578 MiB |\n",
      "|       from large pool |  25899 MiB |  25899 MiB | 114475 MiB |  88576 MiB |\n",
      "|       from small pool |     81 MiB |     81 MiB |     83 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  25925 MiB |  25925 MiB | 114503 MiB |  88578 MiB |\n",
      "|       from large pool |  25844 MiB |  25844 MiB | 114420 MiB |  88576 MiB |\n",
      "|       from small pool |     81 MiB |     81 MiB |     83 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  26318 MiB |  26318 MiB |  29934 MiB |   3616 MiB |\n",
      "|       from large pool |  26236 MiB |  26236 MiB |  29852 MiB |   3616 MiB |\n",
      "|       from small pool |     82 MiB |     82 MiB |     82 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 345048 KiB | 353240 KiB |   7465 MiB |   7128 MiB |\n",
      "|       from large pool | 344576 KiB | 352768 KiB |   7415 MiB |   7079 MiB |\n",
      "|       from small pool |    472 KiB |   2090 KiB |     50 MiB |     49 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    2947    |    2947    |    3875    |     928    |\n",
      "|       from large pool |    1730    |    1730    |    2626    |     896    |\n",
      "|       from small pool |    1217    |    1217    |    1249    |      32    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    2947    |    2947    |    3875    |     928    |\n",
      "|       from large pool |    1730    |    1730    |    2626    |     896    |\n",
      "|       from small pool |    1217    |    1217    |    1249    |      32    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     969    |     969    |    1002    |      33    |\n",
      "|       from large pool |     928    |     928    |     961    |      33    |\n",
      "|       from small pool |      41    |      41    |      41    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     123    |     123    |     336    |     213    |\n",
      "|       from large pool |     121    |     121    |     275    |     154    |\n",
      "|       from small pool |       2    |       5    |      61    |      59    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>claim</th>\n",
       "      <th>check_worthiness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234964653014384644</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/EricTrump/status/123496465...</td>\n",
       "      <td>Since this will never get reported by the medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234869939720216578</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/RealJamesWoods/status/1234...</td>\n",
       "      <td>Thanks, #MichaelBloomberg. Here’s a handy litt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234873136304267267</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/hayxsmith/status/123487313...</td>\n",
       "      <td>Folks, when you say \"The corona virus isn't a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235071285027147776</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/ipspankajnain/status/12350...</td>\n",
       "      <td>Just 1 case of Corona Virus in India and  peop...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234911110861594624</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/PressSec/status/1234911110...</td>\n",
       "      <td>President  @realDonaldTrump  made a commitment...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     topic_id  \\\n",
       "tweet_id                        \n",
       "1234964653014384644  covid-19   \n",
       "1234869939720216578  covid-19   \n",
       "1234873136304267267  covid-19   \n",
       "1235071285027147776  covid-19   \n",
       "1234911110861594624  covid-19   \n",
       "\n",
       "                                                             tweet_url  \\\n",
       "tweet_id                                                                 \n",
       "1234964653014384644  https://twitter.com/EricTrump/status/123496465...   \n",
       "1234869939720216578  https://twitter.com/RealJamesWoods/status/1234...   \n",
       "1234873136304267267  https://twitter.com/hayxsmith/status/123487313...   \n",
       "1235071285027147776  https://twitter.com/ipspankajnain/status/12350...   \n",
       "1234911110861594624  https://twitter.com/PressSec/status/1234911110...   \n",
       "\n",
       "                                                            tweet_text  claim  \\\n",
       "tweet_id                                                                        \n",
       "1234964653014384644  Since this will never get reported by the medi...      1   \n",
       "1234869939720216578  Thanks, #MichaelBloomberg. Here’s a handy litt...      0   \n",
       "1234873136304267267  Folks, when you say \"The corona virus isn't a ...      0   \n",
       "1235071285027147776  Just 1 case of Corona Virus in India and  peop...      1   \n",
       "1234911110861594624  President  @realDonaldTrump  made a commitment...      1   \n",
       "\n",
       "                     check_worthiness  \n",
       "tweet_id                               \n",
       "1234964653014384644                 1  \n",
       "1234869939720216578                 0  \n",
       "1234873136304267267                 0  \n",
       "1235071285027147776                 0  \n",
       "1234911110861594624                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1172 [02:12<42:59:55, 132.19s/it]/tmp/ipykernel_1771071/3923584380.py:52: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
      "100%|██████████| 1172/1172 [22:23<00:00,  1.15s/it] \n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "print(torch.cuda.memory_summary())\n",
    "with open(\"../prompts/CheckThat/standard/zero-shot.txt\", \"r\") as f:\n",
    "    instruction = f.read().replace(\"\\n\", \"\")\n",
    "data = load_check_that_dataset(\n",
    "    \"../data/CheckThat2021Task1a\",\n",
    ")\n",
    "\n",
    "texts = data[\"tweet_text\"]\n",
    "prompts = [f\"{instruction} '''{text}'''\" for text in texts]\n",
    "zeroshot_output = f\"../results/CheckThat/{model_id.name}/zeroshot1.csv\"\n",
    "os.makedirs(os.path.dirname(zeroshot_output), exist_ok=True)\n",
    "\n",
    "class ProgressDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "prompts_data = ProgressDataset(prompts)\n",
    "\n",
    "dataset_with_scores = data.copy()\n",
    "\n",
    "display(data.head())\n",
    "dict_matcher = re.compile(r\"{.*}\")\n",
    "score_matcher = re.compile(r\"([Ss]core[^\\d]*)(\\d+)\")\n",
    "non_check_worthy_matcher = re.compile(\n",
    "    r\"(non-checkworthy)|(not check-worthy)|(non check-worthy)\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    responses = pipe(prompts_data, batch_size=128)\n",
    "    for index, result in enumerate(tqdm(responses, total=len(prompts))):\n",
    "        response = result[0][\"generated_text\"].replace(\"\\n\", \"\")\n",
    "        dataset_index = data.index[index]\n",
    "        try:\n",
    "            parsed_json = json.loads(dict_matcher.search(response).group(0))\n",
    "            dataset_with_scores.loc[dataset_index, \"score\"] = parsed_json[\"score\"]\n",
    "            dataset_with_scores.loc[dataset_index, \"reasoning\"] = parsed_json[\"reasoning\"]\n",
    "        except (json.decoder.JSONDecodeError, AttributeError, KeyError) as e:\n",
    "            # Try to find score\n",
    "            score = score_matcher.search(response)\n",
    "            if score is not None:\n",
    "                score = score[2]\n",
    "            else:\n",
    "                score = 0.0 if non_check_worthy_matcher.search(response) else np.nan\n",
    "            dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
    "            dataset_with_scores.loc[dataset_index, \"reasoning\"] = response\n",
    "            continue\n",
    "columns =  [\"check_worthiness\", \"score\", \"tweet_text\", \"reasoning\"]\n",
    "dataset_with_scores = dataset_with_scores[columns]\n",
    "dataset_with_scores.to_csv(zeroshot_output, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.75876141, 0.56580853, 0.57253337, 0.58373547]), 'score_time': array([0.06997514, 0.00264359, 0.0025599 , 0.00263166]), 'test_f1_macro': array([0.67455571, 0.6385829 , 0.71197057, 0.73045933]), 'test_accuracy': array([0.7337884 , 0.70648464, 0.76109215, 0.80204778])}\n"
     ]
    }
   ],
   "source": [
    "dataset_path = f\"../results/CheckThat/{model_id.name}/zeroshot1.csv\"\n",
    "dataset_with_scores = pd.read_csv(dataset_path, index_col=0)\n",
    "class ThresholdOptimizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.threshold = None\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, y: pd.Series):\n",
    "        \n",
    "        y_gold = x[\"check_worthiness\"].values\n",
    "\n",
    "        reports = []\n",
    "        for threshold in range(1, 100):\n",
    "            y_pred = x[\"score\"].map(lambda x: 1 if x >= threshold else 0).values\n",
    "            report = classification_report(y_gold, y_pred, output_dict=True)\n",
    "            report[\"threshold\"] = threshold\n",
    "            reports.append(report)\n",
    "        self.threshold = max(reports, key=lambda report: report[\"macro avg\"][\"f1-score\"])[\"threshold\"]\n",
    "    \n",
    "    def predict(self, x: pd.DataFrame):\n",
    "        predictions = x[\"score\"].map(lambda x: 1 if x >= self.threshold else 0)\n",
    "        return predictions\n",
    "\n",
    "# Do a four fold cross validation where the threshold is optimized\n",
    "print(cross_validate(\n",
    "    ThresholdOptimizer(),\n",
    "    X=dataset_with_scores,\n",
    "    y=dataset_with_scores[\"check_worthiness\"],\n",
    "    cv=StratifiedKFold(n_splits=4),\n",
    "    scoring=[\"f1_macro\", \"accuracy\"],\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
