{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check-worthiness detection using Large Language Models\n",
    "\n",
    "First, the necessary python modules are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "from claimbuster_utils import load_claimbuster_dataset\n",
    "from checkthat_utils import load_check_that_dataset\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from llm import load_huggingface_model, HuggingFaceModel, run_llm_cross_validation\n",
    "import os\n",
    "from error_analysis import generate_error_analysis_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 720/720 [00:00<?, ?B/s] \n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m model_id \u001b[38;5;241m=\u001b[39m HuggingFaceModel\u001b[38;5;241m.\u001b[39mMIXTRAL_INSTRUCT\n\u001b[1;32m----> 3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m \u001b[43mload_huggingface_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matsb\\source\\repos\\Fake-news-detection\\src\\llm.py:74\u001b[0m, in \u001b[0;36mload_huggingface_model\u001b[1;34m(model_id, bnb_config, max_new_tokens, return_full_text)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_huggingface_model\u001b[39m(\n\u001b[0;32m     67\u001b[0m     model_id: HuggingFaceModel, \n\u001b[0;32m     68\u001b[0m     bnb_config\u001b[38;5;241m=\u001b[39mBNB_CONFIG,\n\u001b[0;32m     69\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[0;32m     70\u001b[0m     return_full_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Pipeline: \n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a Huggingface LLM model as a pipeline. Note that this has only been tested\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    with models from Mistral, so it might not work with other models.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    567\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\matsb\\anaconda3\\envs\\fake-news-detection\\Lib\\site-packages\\transformers\\modeling_utils.py:2945\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2943\u001b[0m         )\n\u001b[0;32m   2944\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 2945\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   2946\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2947\u001b[0m         )\n\u001b[0;32m   2949\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[0;32m   2950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[1;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "model_id = HuggingFaceModel.MIXTRAL_INSTRUCT\n",
    "pipe = load_huggingface_model(model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClaimBuster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m     36\u001b[0m prompts_data \u001b[38;5;241m=\u001b[39m ProgressDataset(prompts)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpipe\u001b[49m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(prompts_data))\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# dataset_with_scores = data.copy()\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# display(data.head())\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# dataset_with_scores = dataset_with_scores[columns]\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# dataset_with_scores.to_csv(zeroshot_output, index=True)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"../prompts/ClaimBuster/standard/zero-shot.txt\", \"r\") as f:\n",
    "    instruction = f.read().replace(\"\\n\", \"\")\n",
    "use_contextual = False\n",
    "data = load_claimbuster_dataset(\n",
    "    \"../data/ClaimBuster_Datasets/datasets\",\n",
    "    use_contextual_features=use_contextual,\n",
    "    debate_transcripts_folder=\"../data/ClaimBuster_Datasets/debate_transcripts\",\n",
    ")[:10]\n",
    "\n",
    "\n",
    "texts = data[\"Text\"]\n",
    "if use_contextual is False:\n",
    "    prompts = [f\"{instruction} '''{text}'''\" for text in texts]\n",
    "    zeroshot_output = f\"../results/ClaimBuster/{model_id.name}/zeroshot1.csv\"\n",
    "    os.makedirs(os.path.dirname(zeroshot_output), exist_ok=True)\n",
    "else:\n",
    "    contexts = data[\"previous_sentences\"].tolist()\n",
    "    prompts = [\n",
    "        f\"{instruction} For context, the following senteces were said prior to the one in question: {context} Only evaluate the check-worthiness of the following sentence: '''{text}'''\"\n",
    "        for text, context in zip(texts, contexts)\n",
    "    ]\n",
    "    zeroshot_output = \"../results/ClaimBuster/zeroshot_contextual.csv\"\n",
    "\n",
    "\n",
    "class ProgressDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "prompts_data = ProgressDataset(prompts)\n",
    "print(pipe.tokenizer.encode(prompts_data))\n",
    "\n",
    "dataset_with_scores = data.copy()\n",
    "\n",
    "display(data.head())\n",
    "dict_matcher = re.compile(r\"{.*}\")\n",
    "score_matcher = re.compile(r\"([Ss]core[^\\d]*)(\\d+)\")\n",
    "non_check_worthy_matcher = re.compile(\n",
    "    r\"(non-checkworthy)|(not check-worthy)|(non check-worthy)\"\n",
    ")\n",
    "\n",
    "responses = pipe(prompts_data, batch_size=128)\n",
    "for index, result in enumerate(tqdm(responses, total=len(prompts))):\n",
    "    response = result[0][\"generated_text\"].replace(\"\\n\", \"\")\n",
    "    dataset_index = data.index[index]\n",
    "    try:\n",
    "        parsed_json = json.loads(dict_matcher.search(response).group(0))\n",
    "        dataset_with_scores.loc[dataset_index, \"score\"] = parsed_json[\"score\"]\n",
    "        dataset_with_scores.loc[dataset_index, \"reasoning\"] = parsed_json[\"reasoning\"]\n",
    "    except (json.decoder.JSONDecodeError, AttributeError, KeyError) as e:\n",
    "        # Try to find score\n",
    "        score = score_matcher.search(response)\n",
    "        if score is not None:\n",
    "            score = score[2]\n",
    "        else:\n",
    "            score = 0.0 if non_check_worthy_matcher.search(response) else np.nan\n",
    "        dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
    "        dataset_with_scores.loc[dataset_index, \"reasoning\"] = response\n",
    "        continue\n",
    "# Set the following column order: Verdict, score, Text, reasoning, previous_sentences\n",
    "columns =  [\"Verdict\", \"score\", \"Text\", \"reasoning\"]\n",
    "if use_contextual:\n",
    "    columns.append(\"previous_sentences\")\n",
    "dataset_with_scores = dataset_with_scores[columns]\n",
    "dataset_with_scores.to_csv(zeroshot_output, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 fold cross validation for model MISTRAL_7B_INSTRUCT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.371314</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.790566</td>\n",
       "      <td>0.807690</td>\n",
       "      <td>0.798018</td>\n",
       "      <td>0.830095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.369287</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>0.803436</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.805089</td>\n",
       "      <td>0.840017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.406544</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.777518</td>\n",
       "      <td>0.788547</td>\n",
       "      <td>0.782555</td>\n",
       "      <td>0.818859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.389679</td>\n",
       "      <td>0.008304</td>\n",
       "      <td>0.794504</td>\n",
       "      <td>0.807362</td>\n",
       "      <td>0.800335</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>1.384206</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>0.791506</td>\n",
       "      <td>0.802604</td>\n",
       "      <td>0.796499</td>\n",
       "      <td>0.830576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fit_time  score_time  ...  test_f1_macro  test_accuracy\n",
       "0        1.371314    0.006999  ...       0.798018       0.830095\n",
       "1        1.369287    0.010589  ...       0.805089       0.840017\n",
       "2        1.406544    0.007000  ...       0.782555       0.818859\n",
       "3        1.389679    0.008304  ...       0.800335       0.833333\n",
       "Average  1.384206    0.008223  ...       0.796499       0.830576\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 fold cross validation for model MIXTRAL_INSTRUCT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.300780</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.783159</td>\n",
       "      <td>0.821010</td>\n",
       "      <td>0.795382</td>\n",
       "      <td>0.820587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.340834</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.783971</td>\n",
       "      <td>0.808995</td>\n",
       "      <td>0.793886</td>\n",
       "      <td>0.823894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.299942</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>0.770906</td>\n",
       "      <td>0.802724</td>\n",
       "      <td>0.781971</td>\n",
       "      <td>0.810587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.465163</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.777252</td>\n",
       "      <td>0.809816</td>\n",
       "      <td>0.788636</td>\n",
       "      <td>0.816377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>1.351680</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>0.778822</td>\n",
       "      <td>0.810636</td>\n",
       "      <td>0.789969</td>\n",
       "      <td>0.817861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fit_time  score_time  ...  test_f1_macro  test_accuracy\n",
       "0        1.300780    0.007999  ...       0.795382       0.820587\n",
       "1        1.340834    0.008000  ...       0.793886       0.823894\n",
       "2        1.299942    0.010236  ...       0.781971       0.810587\n",
       "3        1.465163    0.009000  ...       0.788636       0.816377\n",
       "Average  1.351680    0.008809  ...       0.789969       0.817861\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload\n",
    "# Print the number of empty scores\n",
    "for model_id in HuggingFaceModel:\n",
    "    print(f\"Running 4 fold cross validation for model {model_id.name}\")\n",
    "    dataset_path = f\"../results/ClaimBuster/{model_id.name}/zeroshot1.csv\"\n",
    "    dataset_with_scores = pd.read_csv(dataset_path, index_col=0)\n",
    "    display(run_llm_cross_validation(dataset_with_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#              MISTRAL_7B_INSTRUCT               #\n",
      "#              False positives: 413              #\n",
      "#              False negatives: 624              #\n",
      "#              Empty predictions: 0              #\n",
      "#             Wrong output format: 0             #\n",
      "##################################################\n",
      "#                MIXTRAL_INSTRUCT                #\n",
      "#             False positives: 1193              #\n",
      "#              False negatives: 388              #\n",
      "#              Empty predictions: 8              #\n",
      "#            Wrong output format: 259            #\n",
      "##################################################\n",
      "#                     Total                      #\n",
      "#             False positives: 1324              #\n",
      "#              False negatives: 757              #\n",
      "#        Overlapping false positives: 282        #\n",
      "#        Overlapping false negatives: 255        #\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "mistral_results = pd.read_csv(f\"../results/ClaimBuster/{HuggingFaceModel.MISTRAL_7B_INSTRUCT.name}/zeroshot1.csv\", index_col=0)\n",
    "mixtral_results = pd.read_csv(f\"../results/ClaimBuster/{HuggingFaceModel.MIXTRAL_INSTRUCT.name}/zeroshot1.csv\", index_col=0)\n",
    "results = [mistral_results, mixtral_results]\n",
    "models = [HuggingFaceModel.MISTRAL_7B_INSTRUCT, HuggingFaceModel.MIXTRAL_INSTRUCT]\n",
    "generate_error_analysis_report(\n",
    "    results=results,\n",
    "    models=models,\n",
    "    folder_path=f\"../results/ClaimBuster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CheckThat 2021 Task 1a Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  25981 MiB |  25981 MiB | 114559 MiB |  88578 MiB |\n",
      "|       from large pool |  25899 MiB |  25899 MiB | 114475 MiB |  88576 MiB |\n",
      "|       from small pool |     81 MiB |     81 MiB |     83 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  25981 MiB |  25981 MiB | 114559 MiB |  88578 MiB |\n",
      "|       from large pool |  25899 MiB |  25899 MiB | 114475 MiB |  88576 MiB |\n",
      "|       from small pool |     81 MiB |     81 MiB |     83 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  25925 MiB |  25925 MiB | 114503 MiB |  88578 MiB |\n",
      "|       from large pool |  25844 MiB |  25844 MiB | 114420 MiB |  88576 MiB |\n",
      "|       from small pool |     81 MiB |     81 MiB |     83 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  26318 MiB |  26318 MiB |  29934 MiB |   3616 MiB |\n",
      "|       from large pool |  26236 MiB |  26236 MiB |  29852 MiB |   3616 MiB |\n",
      "|       from small pool |     82 MiB |     82 MiB |     82 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 345048 KiB | 353240 KiB |   7465 MiB |   7128 MiB |\n",
      "|       from large pool | 344576 KiB | 352768 KiB |   7415 MiB |   7079 MiB |\n",
      "|       from small pool |    472 KiB |   2090 KiB |     50 MiB |     49 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    2947    |    2947    |    3875    |     928    |\n",
      "|       from large pool |    1730    |    1730    |    2626    |     896    |\n",
      "|       from small pool |    1217    |    1217    |    1249    |      32    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    2947    |    2947    |    3875    |     928    |\n",
      "|       from large pool |    1730    |    1730    |    2626    |     896    |\n",
      "|       from small pool |    1217    |    1217    |    1249    |      32    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     969    |     969    |    1002    |      33    |\n",
      "|       from large pool |     928    |     928    |     961    |      33    |\n",
      "|       from small pool |      41    |      41    |      41    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     123    |     123    |     336    |     213    |\n",
      "|       from large pool |     121    |     121    |     275    |     154    |\n",
      "|       from small pool |       2    |       5    |      61    |      59    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>claim</th>\n",
       "      <th>check_worthiness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1234964653014384644</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/EricTrump/status/123496465...</td>\n",
       "      <td>Since this will never get reported by the medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234869939720216578</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/RealJamesWoods/status/1234...</td>\n",
       "      <td>Thanks, #MichaelBloomberg. Here’s a handy litt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234873136304267267</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/hayxsmith/status/123487313...</td>\n",
       "      <td>Folks, when you say \"The corona virus isn't a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235071285027147776</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/ipspankajnain/status/12350...</td>\n",
       "      <td>Just 1 case of Corona Virus in India and  peop...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234911110861594624</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>https://twitter.com/PressSec/status/1234911110...</td>\n",
       "      <td>President  @realDonaldTrump  made a commitment...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     topic_id  \\\n",
       "tweet_id                        \n",
       "1234964653014384644  covid-19   \n",
       "1234869939720216578  covid-19   \n",
       "1234873136304267267  covid-19   \n",
       "1235071285027147776  covid-19   \n",
       "1234911110861594624  covid-19   \n",
       "\n",
       "                                                             tweet_url  \\\n",
       "tweet_id                                                                 \n",
       "1234964653014384644  https://twitter.com/EricTrump/status/123496465...   \n",
       "1234869939720216578  https://twitter.com/RealJamesWoods/status/1234...   \n",
       "1234873136304267267  https://twitter.com/hayxsmith/status/123487313...   \n",
       "1235071285027147776  https://twitter.com/ipspankajnain/status/12350...   \n",
       "1234911110861594624  https://twitter.com/PressSec/status/1234911110...   \n",
       "\n",
       "                                                            tweet_text  claim  \\\n",
       "tweet_id                                                                        \n",
       "1234964653014384644  Since this will never get reported by the medi...      1   \n",
       "1234869939720216578  Thanks, #MichaelBloomberg. Here’s a handy litt...      0   \n",
       "1234873136304267267  Folks, when you say \"The corona virus isn't a ...      0   \n",
       "1235071285027147776  Just 1 case of Corona Virus in India and  peop...      1   \n",
       "1234911110861594624  President  @realDonaldTrump  made a commitment...      1   \n",
       "\n",
       "                     check_worthiness  \n",
       "tweet_id                               \n",
       "1234964653014384644                 1  \n",
       "1234869939720216578                 0  \n",
       "1234873136304267267                 0  \n",
       "1235071285027147776                 0  \n",
       "1234911110861594624                 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1172 [02:12<42:59:55, 132.19s/it]/tmp/ipykernel_1771071/3923584380.py:52: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
      "100%|██████████| 1172/1172 [22:23<00:00,  1.15s/it] \n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "print(torch.cuda.memory_summary())\n",
    "with open(\"../prompts/CheckThat/standard/zero-shot.txt\", \"r\") as f:\n",
    "    instruction = f.read().replace(\"\\n\", \"\")\n",
    "data = load_check_that_dataset(\n",
    "    \"../data/CheckThat2021Task1a\",\n",
    ")\n",
    "\n",
    "texts = data[\"tweet_text\"]\n",
    "prompts = [f\"{instruction} '''{text}'''\" for text in texts]\n",
    "zeroshot_output = f\"../results/CheckThat/{model_id.name}/zeroshot1.csv\"\n",
    "os.makedirs(os.path.dirname(zeroshot_output), exist_ok=True)\n",
    "\n",
    "class ProgressDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "prompts_data = ProgressDataset(prompts)\n",
    "\n",
    "dataset_with_scores = data.copy()\n",
    "\n",
    "display(data.head())\n",
    "dict_matcher = re.compile(r\"{.*}\")\n",
    "score_matcher = re.compile(r\"([Ss]core[^\\d]*)(\\d+)\")\n",
    "non_check_worthy_matcher = re.compile(\n",
    "    r\"(non-checkworthy)|(not check-worthy)|(non check-worthy)\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    responses = pipe(prompts_data, batch_size=128)\n",
    "    for index, result in enumerate(tqdm(responses, total=len(prompts))):\n",
    "        response = result[0][\"generated_text\"].replace(\"\\n\", \"\")\n",
    "        dataset_index = data.index[index]\n",
    "        try:\n",
    "            parsed_json = json.loads(dict_matcher.search(response).group(0))\n",
    "            dataset_with_scores.loc[dataset_index, \"score\"] = parsed_json[\"score\"]\n",
    "            dataset_with_scores.loc[dataset_index, \"reasoning\"] = parsed_json[\"reasoning\"]\n",
    "        except (json.decoder.JSONDecodeError, AttributeError, KeyError) as e:\n",
    "            # Try to find score\n",
    "            score = score_matcher.search(response)\n",
    "            if score is not None:\n",
    "                score = score[2]\n",
    "            else:\n",
    "                score = 0.0 if non_check_worthy_matcher.search(response) else np.nan\n",
    "            dataset_with_scores.loc[dataset_index, \"score\"] = score\n",
    "            dataset_with_scores.loc[dataset_index, \"reasoning\"] = response\n",
    "            continue\n",
    "columns =  [\"check_worthiness\", \"score\", \"tweet_text\", \"reasoning\"]\n",
    "dataset_with_scores = dataset_with_scores[columns]\n",
    "dataset_with_scores.to_csv(zeroshot_output, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 fold cross validation for model MISTRAL_7B_INSTRUCT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.726544</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.646576</td>\n",
       "      <td>0.671049</td>\n",
       "      <td>0.652261</td>\n",
       "      <td>0.703072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.665200</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.677212</td>\n",
       "      <td>0.706620</td>\n",
       "      <td>0.685311</td>\n",
       "      <td>0.733788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647787</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.644918</td>\n",
       "      <td>0.680886</td>\n",
       "      <td>0.588405</td>\n",
       "      <td>0.597270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.637105</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>0.547064</td>\n",
       "      <td>0.560726</td>\n",
       "      <td>0.521384</td>\n",
       "      <td>0.549488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.669159</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>0.628943</td>\n",
       "      <td>0.654820</td>\n",
       "      <td>0.611840</td>\n",
       "      <td>0.645904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fit_time  score_time  test_precision_macro  test_recall_macro  \\\n",
       "0        0.726544    0.007985              0.646576           0.671049   \n",
       "1        0.665200    0.009818              0.677212           0.706620   \n",
       "2        0.647787    0.005998              0.644918           0.680886   \n",
       "3        0.637105    0.007004              0.547064           0.560726   \n",
       "Average  0.669159    0.007701              0.628943           0.654820   \n",
       "\n",
       "         test_f1_macro  test_accuracy  \n",
       "0             0.652261       0.703072  \n",
       "1             0.685311       0.733788  \n",
       "2             0.588405       0.597270  \n",
       "3             0.521384       0.549488  \n",
       "Average       0.611840       0.645904  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 4 fold cross validation for model MIXTRAL_INSTRUCT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.634165</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.668719</td>\n",
       "      <td>0.683810</td>\n",
       "      <td>0.674556</td>\n",
       "      <td>0.733788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.639037</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.646314</td>\n",
       "      <td>0.638583</td>\n",
       "      <td>0.706485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.649430</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.702764</td>\n",
       "      <td>0.729317</td>\n",
       "      <td>0.711971</td>\n",
       "      <td>0.761092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.662586</td>\n",
       "      <td>0.005998</td>\n",
       "      <td>0.746323</td>\n",
       "      <td>0.719487</td>\n",
       "      <td>0.730459</td>\n",
       "      <td>0.802048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.646304</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.687960</td>\n",
       "      <td>0.694732</td>\n",
       "      <td>0.688892</td>\n",
       "      <td>0.750853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fit_time  score_time  test_precision_macro  test_recall_macro  \\\n",
       "0        0.634165    0.006297              0.668719           0.683810   \n",
       "1        0.639037    0.008455              0.634033           0.646314   \n",
       "2        0.649430    0.006923              0.702764           0.729317   \n",
       "3        0.662586    0.005998              0.746323           0.719487   \n",
       "Average  0.646304    0.006918              0.687960           0.694732   \n",
       "\n",
       "         test_f1_macro  test_accuracy  \n",
       "0             0.674556       0.733788  \n",
       "1             0.638583       0.706485  \n",
       "2             0.711971       0.761092  \n",
       "3             0.730459       0.802048  \n",
       "Average       0.688892       0.750853  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload\n",
    "for model_id in HuggingFaceModel:\n",
    "    print(f\"Running 4 fold cross validation for model {model_id.name}\")\n",
    "    dataset_path = f\"../results/CheckThat/{model_id.name}/zeroshot/zeroshot1.csv\"\n",
    "    dataset_with_scores = pd.read_csv(dataset_path, index_col=0)\n",
    "    display(run_llm_cross_validation(dataset_with_scores, label_column=\"check_worthiness\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#              MISTRAL_7B_INSTRUCT               #\n",
      "#              False positives: 376              #\n",
      "#              False negatives: 36               #\n",
      "#              Empty predictions: 1              #\n",
      "#             Wrong output format: 0             #\n",
      "##################################################\n",
      "#                MIXTRAL_INSTRUCT                #\n",
      "#              False positives: 484              #\n",
      "#              False negatives: 20               #\n",
      "#              Empty predictions: 3              #\n",
      "#            Wrong output format: 25             #\n",
      "##################################################\n",
      "#                     Total                      #\n",
      "#              False positives: 568              #\n",
      "#              False negatives: 51               #\n",
      "#        Overlapping false positives: 292        #\n",
      "#         Overlapping false negatives: 5         #\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "folder_path = f\"../results/CheckThat\"\n",
    "mistral_results = pd.read_csv(f\"{folder_path}/{HuggingFaceModel.MISTRAL_7B_INSTRUCT.name}/zeroshot1.csv\", index_col=0)\n",
    "mixtral_results = pd.read_csv(f\"{folder_path}/{HuggingFaceModel.MIXTRAL_INSTRUCT.name}/zeroshot1.csv\", index_col=0)\n",
    "results = [mistral_results, mixtral_results]\n",
    "models = [HuggingFaceModel.MISTRAL_7B_INSTRUCT, HuggingFaceModel.MIXTRAL_INSTRUCT]\n",
    "generate_error_analysis_report(\n",
    "    results=results,\n",
    "    models=models,\n",
    "    folder_path=folder_path,\n",
    "    label_column_name=\"check_worthiness\",\n",
    "    text_column_name=\"tweet_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
